{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import time\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import tqdm\n",
    "import os\n",
    "from collections import namedtuple,defaultdict,deque "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment: Sokoban-v1\n"
     ]
    }
   ],
   "source": [
    "chapter = 0\n",
    "level = 5\n",
    "\n",
    "\n",
    "env_name = 'Sokoban-v1'\n",
    "env = gym.make(env_name)\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "env.unwrapped.set_level(chapter,level)\n",
    "env.seed(0)\n",
    "env.reset()\n",
    "print(\"Created environment: {}\".format(env_name))\n",
    "\n",
    "\n",
    "#create Results/Chapter [chapter]/Level [level] folder\n",
    "if not os.path.exists('Results/Chapter '+str(chapter)+'/Level '+str(level)):\n",
    "    os.makedirs('Results/Chapter '+str(chapter)+'/Level '+str(level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map( x,  in_min,  in_max,  out_min,  out_max) :\n",
    "  return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;\n",
    "\n",
    "def greedy_policy(Q,s,eps_comp=1e-8):\n",
    "    #.9 prob of greedy action\n",
    "    #.1 prob of random action\n",
    "    if s not in Q:\n",
    "        Q[s] = np.random.rand(env.action_space.n)\n",
    "    r_choice = 1 -map(eps_comp,0,1,0.1,.6)\n",
    "    if np.random.random() < r_choice:\n",
    "        return np.random.choice(np.arange(env.action_space.n))\n",
    "    else:\n",
    "        max_val = np.max(Q[s])\n",
    "         #find all actions that have the max value and choose one at random\n",
    "        max_actions = np.argwhere(Q[s] == max_val).flatten()\n",
    "        return np.random.choice(max_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SARSA, finished=239;Max reward gained=41.969: 100%|██████████| 1000/1000 [00:28<00:00, 35.34it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.99\n",
    "gamma = 0.8\n",
    "num_episodes = 1000\n",
    "num_timesteps = 50\n",
    "Q = {}\n",
    "pbar = tqdm.tqdm(range(num_episodes),)\n",
    "finished = 0\n",
    "max_reward = 0\n",
    "for episode in pbar:\n",
    "    state = env.reset()\n",
    "    last_reward = 0\n",
    "    for step in range(num_timesteps):\n",
    "        action = greedy_policy(Q,state,episode/num_episodes)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        if next_state not in Q:\n",
    "            Q[next_state] = np.random.rand(env.action_space.n)\n",
    "        a_ = greedy_policy(Q,next_state,episode/num_episodes)\n",
    "        Q[state][action] += alpha * ((reward-last_reward) + gamma * Q[next_state][a_] - Q[state][action])\n",
    "        state = next_state\n",
    "        last_reward = reward\n",
    "        if reward > max_reward:\n",
    "            max_reward = reward\n",
    "        \n",
    "        if done:\n",
    "            if step < num_timesteps-1:\n",
    "                finished +=1\n",
    "            break\n",
    "    pbar.set_description(f'Training SARSA, finished={finished};Max reward gained={round(max_reward,3)}')\n",
    "    if episode % 1000 == 0:\n",
    "        fname = 'Results/Chapter '+str(chapter)+'/Level '+str(level)+'/SARSA_'+str(num_episodes)+'_episodes_temp.bin'\n",
    "        with open(fname, 'wb') as handle:\n",
    "            pickle.dump(Q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "            \n",
    "#save the value function\n",
    "fname = 'Results/Chapter '+str(chapter)+'/Level '+str(level)+'/SARSA_'+str(num_episodes)+'_episodes.bin'\n",
    "with open(fname, 'wb') as handle:\n",
    "    pickle.dump(Q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Texture.__del__ at 0x000001889C1473A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\2023-2024\\RNN\\Sokoban\\SokobanEnv\\lib\\site-packages\\pyglet\\image\\__init__.py\", line 1225, in __del__\n",
      "    self._context.delete_texture(self.id)\n",
      "  File \"d:\\2023-2024\\RNN\\Sokoban\\SokobanEnv\\lib\\site-packages\\pyglet\\gl\\base.py\", line 321, in delete_texture\n",
      "    gl.glDeleteTextures(1, gl.GLuint(texture_id))\n",
      "  File \"d:\\2023-2024\\RNN\\Sokoban\\SokobanEnv\\lib\\site-packages\\pyglet\\gl\\lib.py\", line 52, in errcheck\n",
      "    def errcheck(result, func, arguments):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 23"
     ]
    }
   ],
   "source": [
    "def greedy_policy_pi(V,s):\n",
    "    #.9 prob of greedy action\n",
    "    #.1 prob of random action\n",
    "\n",
    "    if s not in V:\n",
    "        V[s] = np.zeros(env.action_space.n)\n",
    "    r_choice = .2\n",
    "    if np.random.random() < r_choice:\n",
    "        return np.random.choice(np.arange(env.action_space.n))\n",
    "    else:\n",
    "        max_val = np.max(V[s])\n",
    "         #find all actions that have the max value and choose one at random\n",
    "        max_actions = np.argwhere(V[s] == max_val).flatten()\n",
    "        return np.random.choice(max_actions)\n",
    "\n",
    "for i in range(1000):\n",
    "    time.sleep(1)\n",
    "    _ = env.reset()\n",
    "    state = env.unwrapped.serialize_state()\n",
    "    st_time = time.time()\n",
    "    done = False\n",
    "    t= 0\n",
    "    last_reward = 0\n",
    "    last_time = time.time()\n",
    "    last_state = state\n",
    "    rendered_frame = 0\n",
    "    while True:\n",
    "        if time.time() - st_time < .2:\n",
    "            env.render()\n",
    "            rendered_frame += 1\n",
    "            time.sleep(1/64)\n",
    "            if (time.time() - last_time) > 1:\n",
    "                print(f'\\rFPS: {rendered_frame}',end='')\n",
    "                rendered_frame = 0\n",
    "                last_time = time.time()\n",
    "            continue\n",
    "        st_time = time.time()\n",
    "        action_time = time.time()\n",
    "        action = greedy_policy_pi(Q,state)\n",
    "        \n",
    "        state, reward, done, info = env.step(action)\n",
    "        state = env.unwrapped.serialize_state()\n",
    "        #print(f'{ACTION_LOOKUP[action]} state change: {last_state != state}',end=' ')\n",
    "        last_state = state\n",
    "        last_reward = reward\n",
    "        t += 1\n",
    "        if done or t > 150:\n",
    "            env.render()\n",
    "            break\n",
    "        env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SokobanEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
