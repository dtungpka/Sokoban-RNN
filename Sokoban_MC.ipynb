{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import time\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import tqdm\n",
    "import os\n",
    "from collections import namedtuple,defaultdict,deque "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment: Sokoban-v1\n"
     ]
    }
   ],
   "source": [
    "env_name = 'Sokoban-v1'\n",
    "env = gym.make(env_name)\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "env.unwrapped.set_level(0,1)\n",
    "env.seed(0)\n",
    "env.reset()\n",
    "print(\"Created environment: {}\".format(env_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(V,s):\n",
    "    #.9 prob of greedy action\n",
    "    #.1 prob of random action\n",
    "\n",
    "    if s not in V:\n",
    "        V[s] = np.zeros(env.action_space.n)\n",
    "    r_choice = .4\n",
    "    if np.random.random() < r_choice:\n",
    "        return np.random.choice(np.arange(env.action_space.n))\n",
    "    else:\n",
    "        max_val = np.max(V[s])\n",
    "         #find all actions that have the max value and choose one at random\n",
    "        max_actions = np.argwhere(V[s] == max_val).flatten()\n",
    "        return np.random.choice(max_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 105.71it/s]\n"
     ]
    }
   ],
   "source": [
    "EVERY_VISIT_MC = False\n",
    "EPISODES = 1000\n",
    "\n",
    "V = {}\n",
    "total_returns = {}\n",
    "N = {}\n",
    "for episode in tqdm.tqdm(range(EPISODES)):\n",
    "    \n",
    "    visited = []\n",
    "    env.reset()\n",
    "    state = env.unwrapped.serialize_state()\n",
    "    done = False\n",
    "    for t in range(20):\n",
    "        action_time = time.time()\n",
    "        if done:\n",
    "            break\n",
    "        action = greedy_policy(V,state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = env.unwrapped.serialize_state()\n",
    "        if EVERY_VISIT_MC or (not EVERY_VISIT_MC and state not in visited):\n",
    "            if not EVERY_VISIT_MC:\n",
    "                visited.append(state)\n",
    "            if state not in total_returns:\n",
    "                total_returns[state] = np.zeros(env.action_space.n)\n",
    "            for _state in total_returns:\n",
    "                total_returns[_state][action] += reward\n",
    "            if state not in N:\n",
    "                N[state] = np.zeros(env.action_space.n)\n",
    "            \n",
    "            N[state][action] += 1\n",
    "            V[state][action] = (total_returns[state][action] / N[state][action])\n",
    "        state = next_state\n",
    "\n",
    "            \n",
    "#save the value function\n",
    "with open('value_function_1.pickle', 'wb') as handle:\n",
    "    pickle.dump(V, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([649., 115.,  84., 152.]), array([627., 111.,  88., 119.]), array([118.,  23.,  24.,  62.]), array([41., 14., 20., 31.]), array([600.,  96.,  87., 130.]), array([583., 114.,  89., 101.]), array([572.,  95.,  92., 103.]), array([571.,  82.,  89.,  90.]), array([77., 19., 24., 14.]), array([12.,  2.,  2.,  7.]), array([6., 0., 1., 1.]), array([77.,  6., 10., 12.]), array([9., 5., 1., 0.]), array([558.,  77.,  93.,  85.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([67., 20.,  3., 16.]), array([11.,  3.,  5.,  2.]), array([0., 1., 0., 3.]), array([541.,  80.,  77.,  86.]), array([62., 11.,  4., 23.]), array([14.,  3.,  2.,  6.]), array([0., 1., 1., 0.]), array([5., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 2., 0., 0.]), array([1., 0., 0., 0.])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 30010004000053 Action: right Value: 20.657673343604998\n",
      "State: 30001004000053 Action: right Value: 21.382488038276943\n",
      "State: 30100004000053 Action: right Value: 111.38644067796322\n",
      "State: 31000004000053 Action: right Value: 306.04073170730965\n",
      "State: 30000104000053 Action: right Value: 22.34798333333274\n",
      "State: 30000014000053 Action: right Value: 23.000566037735233\n",
      "State: 30000001400053 Action: right Value: 23.399842657342035\n",
      "State: 30000000140053 Action: right Value: 23.485043782836502\n",
      "State: 30000010400053 Action: right Value: 173.01870129869673\n",
      "State: 30000100400053 Action: right Value: 917.8808333333131\n",
      "State: 30001000400053 Action: left Value: 673.8000000000017\n",
      "State: 30000001040053 Action: right Value: 172.1037662337617\n",
      "State: 30000010040053 Action: right Value: 1446.189999999963\n",
      "State: 30000000014053 Action: right Value: 23.976810035841655\n",
      "State: 30000100040053 Action: right Value: 0.0\n",
      "State: 30001000040053 Action: right Value: 0.0\n",
      "State: 30010000040053 Action: right Value: 0.0\n",
      "State: 30000000104053 Action: right Value: 196.61149253730824\n",
      "State: 30000001004053 Action: right Value: 1111.5018181817914\n",
      "State: 30000010004053 Action: left Value: 39.20666666666666\n",
      "State: 30000000001453 Action: right Value: 24.35672828096054\n",
      "State: 30000000010453 Action: right Value: 210.53193548386545\n",
      "State: 30000000100453 Action: right Value: 812.8178571428386\n",
      "State: 30000100004053 Action: up Value: 5.77\n",
      "State: 30000001000453 Action: right Value: 2038.6679999999574\n",
      "State: 30000010000453 Action: right Value: 0.0\n",
      "State: 30010000400053 Action: up Value: 32.15\n",
      "State: 30100000400053 Action: right Value: 0.7999999999999998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for s in V:\n",
    "    argmax = np.argmax(V[s])\n",
    "    max_val = np.max(V[s])\n",
    "    s = s[26:40]\n",
    "    print(\"State: {} Action: {} Value: {}\".format(s,ACTION_LOOKUP[argmax],max_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy_pi(V,s):\n",
    "    #.9 prob of greedy action\n",
    "    #.1 prob of random action\n",
    "    return np.argmax(V[s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = env.reset()\n",
    "state = env.unwrapped.serialize_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: right Reward: 1.99\n",
      "Action: right Reward: 1.98\n",
      "Action: right Reward: 1.97\n",
      "Action: right Reward: 1.96\n",
      "Action: right Reward: 1.95\n",
      "Action: right Reward: 1.94\n",
      "Action: right Reward: 1.93\n",
      "Action: right Reward: 13.92\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "done = False\n",
    "while not done:\n",
    "    if time.time() - st_time < .2:\n",
    "        env.render()\n",
    "        continue\n",
    "    st_time = time.time()\n",
    "    action_time = time.time()\n",
    "    action = greedy_policy_pi(V,state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    next_state = env.unwrapped.serialize_state()\n",
    "    print(\"Action: {} Reward: {}\".format(ACTION_LOOKUP[action],reward))\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: push up Reward: -35.60000000000006\n"
     ]
    }
   ],
   "source": [
    "\n",
    "action = 0\n",
    "next_state, reward, done, info = env.step(action)\n",
    "env.render()\n",
    "print(\"Action: {} Reward: {}\".format(ACTION_LOOKUP[action],reward))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SokobanEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
